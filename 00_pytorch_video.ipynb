{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcbqFR0NO/K8V5/Kj3WObY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youse0ng/pytorch_practice/blob/main/00_pytorch_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 00. Pytorch fundamental\n",
        "\n",
        "---\n",
        "https://www.learnpytorch.io/\n",
        "---\n",
        "https://github.com/mrdbourke/pytorch-deep-learning"
      ],
      "metadata": {
        "id": "JlIEMHCo2fQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "zSo9bmn92VmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Introduction to Tensors\n",
        "\n",
        "##Creating tensors"
      ],
      "metadata": {
        "id": "CHwIY11WK8LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scalar\n",
        "\n",
        "scalar=torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "id": "3dNOH3qvc8Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim\n",
        "# 스칼라는 dimension이 없다. 단순히 숫자일뿐"
      ],
      "metadata": {
        "id": "i1yZjR6ceIZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.item()\n",
        "# 파이썬 정수로 돌려줌\n",
        "# Get tensor back as Python int\n"
      ],
      "metadata": {
        "id": "oSmP70APerxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector\n",
        "vector=torch.tensor([7,7])\n",
        "vector"
      ],
      "metadata": {
        "id": "SbzoIumpenNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim\n",
        "#얼마나 많은 차원을 가지고 잇는지 기억하는 것은 대괄호의 수 이다.\n",
        "# 1 출력"
      ],
      "metadata": {
        "id": "yX7buyOkhBfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape\n",
        "#2 출력\n",
        "#2*1 요소를 가지고 있다."
      ],
      "metadata": {
        "id": "-js1iPGrhXWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX\n",
        "MATRIX= torch.tensor([[7,8],\n",
        "                      [9,10]])\n",
        "MATRIX"
      ],
      "metadata": {
        "id": "2TdC17lvhuxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "id": "qZd6SbJ3iRoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[0]"
      ],
      "metadata": {
        "id": "0auts2hQiUln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "id": "1tGukdSfie8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR\n",
        "TENSOR=torch.tensor([[[1,2,3],\n",
        "                      [3,6,9],\n",
        "                      [2,4,6]]])\n",
        "\n",
        "TENSOR"
      ],
      "metadata": {
        "id": "RLrFFXBvin2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "id": "EohularHjMPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "id": "o8wORSEGjVGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random  tensors\n",
        "\n",
        "why random tensors?\n",
        "\n",
        "Random tensors are important because the way neural networks learn is that they start with tensors full of random numbers and then adjust thos random numbers to better represent the data.\n",
        "\n",
        "'Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers'\n",
        "\n",
        "---\n",
        "\n",
        "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html"
      ],
      "metadata": {
        "id": "XsCpoXwlOgjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random tensors of size(3,4)\n",
        "random_tensor=torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "P-Fh5pYcPI4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "\n",
        "random_image_size_tensor=torch.rand(size=(224,224,3)) #height,width,color channels (R,G,B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "id": "uX2TDvVxG_cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "이미지 텐서를 매우 일반적인 방법으로 표현하는 방법 중(텐서형식으로 숫자 인코딩하려는 경우)\n",
        "\n",
        "하나는 색상 채널로 분할하는 것이다.\n",
        "\n",
        "왜냐하면 빨강 녹색 및 파랑으로 거의 모든 색상을 만들 수 있기 때문에\n",
        "\n",
        "(Color channel, height, width)"
      ],
      "metadata": {
        "id": "O8ZuVffjHwq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_size_tensor=torch.rand(size=(3,4))\n",
        "random_image_size_tensor"
      ],
      "metadata": {
        "id": "04W7_UCtIi_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros and Ones"
      ],
      "metadata": {
        "id": "L0pSRPVgJhQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all Zeros\n",
        "\n",
        "zero= torch.zeros(size=(3,4))\n",
        "zero"
      ],
      "metadata": {
        "id": "R06EZsrfJmjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero*random_image_size_tensor"
      ],
      "metadata": {
        "id": "QeCNQfrvJ8so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones=torch.ones(size=(3,4))\n",
        "ones"
      ],
      "metadata": {
        "id": "asg60QYFKOJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype"
      ],
      "metadata": {
        "id": "WDmVJIH7KMV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "XP8fc1VrUt7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.range()\n",
        "# 비정확성 그래서 대신 arange(사용)\n",
        "a=torch.range(0,10)\n",
        "b=torch.arange(0,10)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "uUV1-H4ZU0TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten=torch.arange(1,11)\n",
        "one_to_ten"
      ],
      "metadata": {
        "id": "Q5BC8nn2Vt6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like (특정 텐서와 같은 shape의 텐서 만들)\n",
        "ten_zeros=torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros\n",
        "# ten_zeros 에 one_to ten과 같은 형태(shape)의 0으로 가득찬 텐서를 대입해줘"
      ],
      "metadata": {
        "id": "f-k6VdFkWfet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with Pytorch & Deep learning:\n",
        "\n",
        "텐서 데이터타입은 당신이 Pytorch와 딥러닝을 하면서 만나게될 큰 3가지 에러 중 하나입니다.\n",
        "1. Tensors not right datatype (맞지 않은 데이터 형식의 텐서)\n",
        "\n",
        "ex) float 16텐서와 float32인 텐서를 사용하여 계산을 시도하면 맞지않는다고 에러라 뜰 수 있다.\n",
        "2. Tensors not right shape\n",
        "\n",
        "ex) 매트릭스 증강에 들어가면 한 텐서가 특정형태이고 다른 텐서가 다른 특정형태 즉 둘이 형태가 같지않다면 발생할 수 있는 에러이다.\n",
        "\n",
        "3. Tensors not on the right device\n",
        "\n",
        "ex) \"cpu\"와 \"cuda\" 한 텐서가 \"cpu\" 상에 존재하고 다른 텐서가 \"cuda\"상에 존재하여 둘이 계산하는 경우 에러가 발생할 수 있다. 같지 않은 device에 존재하기 때문\n"
      ],
      "metadata": {
        "id": "4rsfClVSXgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor=torch.tensor([3.0,6.0,9.0],\n",
        "                             dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
        "                             device=None, # what device is your tensor on 어떤 장치로 텐서를 정의했는가?\n",
        "                             requires_grad=False) # whether or not to track gradients with this tensor operation 이 연산에서 그레디언트를 추적할 것인가 말것인가?\n",
        "float_32_tensor"
      ],
      "metadata": {
        "id": "Cf_F_0tXYzHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서를 만들 때 가장 중요한 세가지 매개변수\n",
        "\n",
        " dtype= None\n",
        "\n",
        " 데이터 타입은 컴퓨팅의 연산 정밀도(정확성)와 컴퓨팅 속도 관련있다. (메모리를 덜 차지하는 숫자에 대해 더 빠른 연산을 하기 때문에)\n",
        "\n",
        " device=False or True\n",
        "\n",
        " requires_grad=False or True"
      ],
      "metadata": {
        "id": "Kya5yqRdZdij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "id": "aJdPmhKPZGWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor=float_32_tensor.type(torch.float16) #float_32_tensor.type(torch.half)\n",
        "float_16_tensor"
      ],
      "metadata": {
        "id": "bz-k2mpGeYoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor* float_32_tensor\n",
        "# 지금은 작동하지만 큰 뉴럴네트워크에서는 에러가 나올 수 있다."
      ],
      "metadata": {
        "id": "7mmPeyK5gXNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting information from Tensors (Tensor Attributes)\n",
        "\n",
        "1. Tensors not right datatype - to do get datatype from a tensor, can use 'tensor.dtype'\n",
        "2. Tensors not right shape -to get shape from a tensor, can use 'tensor.shape'\n",
        "3. Tensors not on the right device  -to get device from a tensor, can use 'tensor.device'"
      ],
      "metadata": {
        "id": "cQrUoefDhnhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tebsir\n",
        "some_tensor=torch.rand(3,4,device=\"cuda\")\n",
        "some_tensor"
      ],
      "metadata": {
        "id": "qFhxXoVTk5dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor.size() # function"
      ],
      "metadata": {
        "id": "6_AnwIFdlcMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor.shape # attribution"
      ],
      "metadata": {
        "id": "GUMwDelflpfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out details about some tensor\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor:{some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor:{some_tensor.shape}\")\n",
        "print(f\"Device tensor is on:{some_tensor.device}\")"
      ],
      "metadata": {
        "id": "WzVBudBMlBI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating tensors (Tensors Operations)\n",
        "\n",
        "Tensor Operations include:\n",
        "* addition\n",
        "* substraction\n",
        "* Multiplication (element-wise) #원소간 곱\n",
        "* Division\n",
        "* Matrix multiplication # 행렬 곱셈"
      ],
      "metadata": {
        "id": "bqEySvDHp2KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and add 10 to it\n",
        "tensor=torch.tensor([1,2,3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "id": "y3KkPk97rPA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply tensor by 10\n",
        "\n",
        "tensor * 10"
      ],
      "metadata": {
        "id": "SWuD3yrtraVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Element wise Multiply tensor\n",
        "tensor * tensor"
      ],
      "metadata": {
        "id": "PWQUAIjGujuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substract 10\n",
        "\n",
        "tensor -10"
      ],
      "metadata": {
        "id": "SCoQGsdprok6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out Pytorch in-built functions\n",
        "torch.mul(tensor,10)"
      ],
      "metadata": {
        "id": "85yIgCDWrxDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication  행렬 곱셈\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (Dot product)\n",
        "\n",
        "There are two rules that performing matrix multiplication needs to satisfy:\n",
        "1. The **inner dimensions** must match:\n",
        "* '(3,2) @ (3,2)' won't work\n",
        "* '(2,3) @ (3,2)' will work\n",
        "* '(3,2) @ (2,3)' will work\n",
        "2. The resulting Matrix has shape of the **outer dimentsions**\n",
        "* '(2,3) @ (3,2)' -> '(2,2)'\n",
        "* '(3,2) @ (2,3)' -> '(3,3)'"
      ],
      "metadata": {
        "id": "fJfM5T9jsBsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elment wise multiplication\n",
        "\n",
        "print(tensor , '*', tensor )\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ],
      "metadata": {
        "id": "dxdVPsqWtfOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication (Mat Mul 함수를 이용하여 행렬곱 계산이 더 유리하다)\n",
        "\n",
        "torch.matmul(tensor,tensor)"
      ],
      "metadata": {
        "id": "wkJMbmCRttqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "id": "KSHhT1xduL-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication by hand\n",
        "\n",
        "1*1+2*2+3*3"
      ],
      "metadata": {
        "id": "UeEWVYzKuOyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "value=0\n",
        "for i in range (len(tensor)):\n",
        "  value+= tensor[i]*tensor[i]\n",
        "  print(value)"
      ],
      "metadata": {
        "id": "TA7vOymnuXC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor,tensor)"
      ],
      "metadata": {
        "id": "EkFJISpnvW1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loop 반복문을 사용하여 Mat Mul을 하면 느리다."
      ],
      "metadata": {
        "id": "5x2e5v-Cvdxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One of the most common errors in deep learning : shape errors\n",
        "\n",
        "http://matrixmultiplication.xyz/"
      ],
      "metadata": {
        "id": "ckBdLDO-vkI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_a= torch.tensor([[1,2],\n",
        "                        [3,4],\n",
        "                        [5,6]])\n",
        "tensor_b=torch.tensor([[7,10],\n",
        "                       [8,11],\n",
        "                       [9,12]])\n",
        "\n",
        "torch.mm(tensor_a,tensor_b) # torch.mm is the same as torch.matmul (it's an alias for writing less code)"
      ],
      "metadata": {
        "id": "QwvcBX-32Sr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix out tensor shape issues, we can manipulate the shape of one of our tensors using **transpose**\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor"
      ],
      "metadata": {
        "id": "KfziewsQ16oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_b.T, tensor_b.T.shape"
      ],
      "metadata": {
        "id": "uNRi26_B9MuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matrix multiplication operation works when tensor_b is transposed\n",
        "print(f\"Original shapes: tensor_a={tensor_a.shape}, tensor_b={tensor_b.shape}\")\n",
        "print(f\"New Shapes: tensor_a={tensor_a.shape} (same shape as above), tensor_b.T={tensor_b.T.shape}\")\n",
        "print(f\"Multiplying :{tensor_a.shape} @ {tensor_b.shape} <- inner dimensions must match\")\n",
        "print(\"Output:\\n\")\n",
        "output=torch.matmul(tensor_a,tensor_b.T)\n",
        "print(output)\n",
        "print(f\"\\n Output shape:{output.shape}\")"
      ],
      "metadata": {
        "id": "BaZSjMHg96dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the min,max,mean,sum,etc (tensor aggregation)\n",
        "위의 값을 찾는다면 그걸 tensor aggregation이라 한다.\n",
        "보통 큰 숫자 (텐서와같은)가 작은 숫자로 바뀌니까요"
      ],
      "metadata": {
        "id": "gWaNWVn2Agqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "uopTabE2WmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x=torch.arange(0,100,10)\n",
        "x"
      ],
      "metadata": {
        "id": "Nn2_dEKWAu2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the min\n",
        "torch.min(x),x.min()"
      ],
      "metadata": {
        "id": "oCKOw5HhWj35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Max\n",
        "torch.max(x), x.max()"
      ],
      "metadata": {
        "id": "ZxbQobsGWwlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the Mean\n",
        "x.dtype # int64\n",
        "torch.mean(x)\n",
        "# 올바른 유형의 데이터 타입이 아니라고 뜰것임 위의 대표적인 오류 1번 등장"
      ],
      "metadata": {
        "id": "XNy7ICB0W1u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the mean -note: the torch.mean() function requires a tensor of float32 datatype to work\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ],
      "metadata": {
        "id": "USAPt16XXkXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the sum\n",
        "torch.sum(x), x.sum()"
      ],
      "metadata": {
        "id": "XAFwn-QnYPWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the positional min and max"
      ],
      "metadata": {
        "id": "KhFFwmWOLRIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "7aU7p9wleny4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.argmin()\n",
        "#인덱스값이 추출"
      ],
      "metadata": {
        "id": "R_4OYbIQqKhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.argmax()\n",
        "#인덱스 값이 추출"
      ],
      "metadata": {
        "id": "PGn1M6qAqCHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[x.argmax()]"
      ],
      "metadata": {
        "id": "w35EL1SLqQa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors (시제의 형태와 차원 문제를 해결하는데 도움)\n",
        "\n",
        "*Reshaping - reshapes an input tensor to a defined shape\n",
        "\n",
        "*View -Return a view of an input tensor of certain\n",
        "shape but keep the same memory as the original tensor\n",
        "\n",
        "*Stacking - combine multiple tensors on top of each other (vstack) or side by side(hstack)\n",
        "\n",
        "*Squeeze - removes all '1' dimensions from a tensor\n",
        "\n",
        "*Unsqueeze - add a '1' dimension to a target tensor\n",
        "\n",
        "*permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "l4sm3h3mrrZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "omhJx-b8tJ_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a tensor\n",
        "import torch\n",
        "x=torch.arange(1.,10.)\n",
        "x,x.shape"
      ],
      "metadata": {
        "id": "xRS9rs_BIQKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add an extra dimension\n",
        "x_reshaped=x.reshape(1,7)\n",
        "\n",
        "# 에러가 난다. x의 원소는 지금 9개가 존재하는데,\n",
        "# reshape (1,7) 벡터로 만들라고하면 나머지 2개의 원소는 있을 자리가 없다"
      ],
      "metadata": {
        "id": "LAMlpsNNITa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#따라서 원래 텐서의 원소 갯수와 shape하려는 크기의 원소의 갯수와 맞춰야함\n",
        "#그리고 차원이 하나더 늘어나는 걸 확인\n",
        "x_reshaped=x.reshape(1,9)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "id": "RRHI6Nj_Jxfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped2=x.reshape(3,3)\n",
        "x_reshaped2"
      ],
      "metadata": {
        "id": "ZKCP6RVlhZ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view\n",
        "\n",
        "z=x.view(1,9)\n",
        "z,z.shape"
      ],
      "metadata": {
        "id": "UqNaSVdav7DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
        "z[:,0]=5\n",
        "z,x\n",
        "# z를 바꾸면 x도 따라바뀐다 메모리 공"
      ],
      "metadata": {
        "id": "H76NJrapuJB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on the top of each other\n",
        "x_stacked=torch.stack([x,x,x,x], dim=1)\n",
        "x_stacked"
      ],
      "metadata": {
        "id": "oUvRdrxh30Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze()-removes all single dimensions from a target tensor\n",
        "x_reshaped"
      ],
      "metadata": {
        "id": "bICzBkNPIsFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.shape"
      ],
      "metadata": {
        "id": "xO9pps5wJwVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.squeeze()"
      ],
      "metadata": {
        "id": "kNC-X9IeJyWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.squeeze().shape"
      ],
      "metadata": {
        "id": "9VdvKMRdJ2S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=x_reshaped.reshape(1,1,9)\n",
        "y"
      ],
      "metadata": {
        "id": "Nj2VuYfFKBuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=y.squeeze()\n",
        "y.shape\n",
        "# 단일 차원을 모두 제거해준다. (removes all *single* dimensions)\n",
        "# 그래서 y.shape=[1,1,9]-->[1,9]로 제거해주는 줄 알았지만, 사실은[9]로 만들어주었다."
      ],
      "metadata": {
        "id": "hQRbEpPfKIEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor:{x_reshaped}\")\n",
        "print(f\"Previous shape:{x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from x_reshaped\n",
        "x_squeezed=x_reshaped.squeeze()\n",
        "print(f\"\\n New tensor:{x_squeezed}\")\n",
        "print(f\"New shape:{x_squeezed.shape}\")"
      ],
      "metadata": {
        "id": "VyDVlDFeKlyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze()-adds a single dimension to a target tensor at a specific dim (dimension)\n",
        "print(f\"Previous tensor:{x_squeezed}\")\n",
        "print(f\"Previous shape:{x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed=x_squeezed.unsqueeze(dim=0)  # Shape = torch.Size([])에서 인덱스가 0번인 곳에 차원 추가\n",
        "#dim=1 shape에서 인덱스가 1번인 곳에 차원을 추가\n",
        "print(f\"New tensor:{x_unsqueezed}\")\n",
        "print(f\"New tensor shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "id": "kHpUmArMLe0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "# permute 는 메모리를 공유한다 View와 마찬가지로\n",
        "\n",
        "x_original =torch.rand(size=(224,224,3)) # [height, width, color_channels]\n",
        "\n",
        "# Permute the original tensor to arrange the axis(or dim) order\n",
        "x_permuted = x_original.permute(2,0,1) # shifts axis 0->1, 1->2 ,2->0\n",
        "\n",
        "print(f\"Previous shape= {x_original.shape}\")\n",
        "print(f\"New shape={x_permuted.shape}\") # [color_channel,height,width]"
      ],
      "metadata": {
        "id": "IQPvaAmoNKox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_original)"
      ],
      "metadata": {
        "id": "O2_PHbAUPGVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_original # 224 224 3"
      ],
      "metadata": {
        "id": "jfywzMqePhC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_permuted #3 224 224"
      ],
      "metadata": {
        "id": "anJw5NDVPWJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_x=torch.rand(3,10,10)\n",
        "print(look_x)"
      ],
      "metadata": {
        "id": "hCjfJaaKYnxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_x[2,1,:]"
      ],
      "metadata": {
        "id": "fVFr1r8-pyMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with Numpy."
      ],
      "metadata": {
        "id": "_nyu5BtT-0JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x=torch.arange(1,10).reshape(1,3,3)\n",
        "x"
      ],
      "metadata": {
        "id": "Yau-oXelG2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's index on our new tensor\n",
        "x[0]"
      ],
      "metadata": {
        "id": "8nW4ja6WHOrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's index on the middle bracket (dim=1)\n",
        "x[0][0]"
      ],
      "metadata": {
        "id": "ZHnanMLDHbYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's index on the most inner bracket (last dimension)\n",
        "x[0][2][2]"
      ],
      "metadata": {
        "id": "m4guB-t7HmJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "x[:,0]"
      ],
      "metadata": {
        "id": "foA0Em3oI1hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 세로 1번 인덱싱의 열뽑아내기\n",
        "x[:,:,1]"
      ],
      "metadata": {
        "id": "TBTyO8b3JBV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5를 뽑아내봐\n",
        "x[:,1,1],x[0][1][1]"
      ],
      "metadata": {
        "id": "NAj0N5SiJa33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[1,2,3] 뽑아봐\n",
        "x[:,0],x[0][0]"
      ],
      "metadata": {
        "id": "pqWTZTx9KHoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on x to return 9\n",
        "print(x[:])\n",
        "print(x[:,2]) # 브라켓이 있음\n",
        "print(x[:,2,2])\n",
        "\n",
        "print(x[0])\n",
        "print(x[0][2]) # 브라켓이 없음\n",
        "print(x[0][2][2])"
      ],
      "metadata": {
        "id": "VbZdy1R7K2Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch tensors & Numpy\n",
        "\n",
        "Numpy is a popular scientific Python numerical computing Library\n",
        "\n",
        "And because of this, Pytorch has functionality to interact with it.\n",
        "\n",
        "* Data in Numpy, want in Pytorch Tensor -> 'torch.from_numpy(ndarray)'\n",
        "* Pytorch tensor-> Numpy -> \"torch.Tensor.numpy()\n",
        "\""
      ],
      "metadata": {
        "id": "dLdB6qaqNYw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy array to tensor\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array=np.arange(1.0,8.0)\n",
        "tensor=torch.from_numpy(array)\n",
        "array,tensor\n",
        "array.dtype"
      ],
      "metadata": {
        "id": "FCHkxnVaZ5-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array.dtype\n",
        "#원래 Pytorch의 기본 데이터 유형 float32이다."
      ],
      "metadata": {
        "id": "b-_ICynImDEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형 변경\n",
        "tensor=torch.from_numpy(array).type(torch.float32)\n",
        "# When converting from numpy -> Pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise"
      ],
      "metadata": {
        "id": "52mjWygXSq4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array,tensor"
      ],
      "metadata": {
        "id": "d9FGAsmybPbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the value of array, what will this do to 'tensor'?\n",
        "array=array+1\n",
        "array,tensor\n",
        "# 정답은 어레이의 요소값을 변경해도 텐서의 요소값은 변경되지 않는다. 메모리 공유 x"
      ],
      "metadata": {
        "id": "Km23-QRraZyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor to Numpy array\n",
        "tensor=torch.ones(7) #default tensor datatype float32\n",
        "numpy_tensor= tensor.numpy()\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "id": "LNUyxO4Cbpd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_tensor.dtype\n",
        "# 넘파이의 기본 데이터 유형은 float64 이고 pytorch의 기본 데이터 유형은 float32이다."
      ],
      "metadata": {
        "id": "-kIYYHmVekr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the tensor, whaat happens to 'numpy_tensor'?\n",
        "# 텐서를 변경하면 넘파이로변경된 텐서는 어떻게될까요?\n",
        "# 메모리 공유하지않는다.\n",
        "tensor=tensor+1\n",
        "tensor,numpy_tensor"
      ],
      "metadata": {
        "id": "d3-Xc6jcey-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Reproducibility (trying to take random out of random)\n",
        " 간단히 말해서 신경망이 학습하는 방식은 난수로 부터 시작된다.\n",
        "그 후 텐서연산을 진행하고 난수를 업데이트하며\n",
        "데이터를 더 잘 표현하도록 시도한다.\n",
        "하지만 이러한 것을 친구와 공유할 때 문제가 발생한다.\n",
        "\n",
        "그래서\n",
        "신경망의 무작위성을 줄이기 위해 파이토치는\n",
        "**random seed** 라는 개념을 도입했다.\n"
      ],
      "metadata": {
        "id": "rzhTUD1KfJL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# create two random tensors\n",
        "random_tensor_a=torch.rand(3,4)\n",
        "random_tensor_b=torch.rand(3,4)\n",
        "print(random_tensor_a)\n",
        "print(random_tensor_b)\n",
        "print(random_tensor_a==random_tensor_b)"
      ],
      "metadata": {
        "id": "2_eDypeKfdwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "# 난수이지만 재현 가능한 텐서를 만들어보자\n",
        "\n",
        "import torch\n",
        "\n",
        "# Set the random seed\n",
        "RANDOM_SEED=42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_c=torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_d=torch.rand(3,4)\n",
        "print(random_tensor_c)\n",
        "print(random_tensor_d)\n",
        "print(random_tensor_c==random_tensor_d)"
      ],
      "metadata": {
        "id": "QFaEgcUBgEbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors and Pytorch objects on the GPUs(and making faster computations)\n"
      ],
      "metadata": {
        "id": "u15EQNhvkVkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest- Use google colab for a free GPU (options to upgrad as well)\n",
        "2. Use your own GPU- takse a little bit of setup and requires the investment of purchasing a GPU,there's lots of options\n",
        "3. Use cloud computing -GCP,Azure,AWS, these service allow you to rent computers on the cloud and access them\n",
        "\n",
        "2,3번은 파이토치와 gpu 드라이버 (CUDA)의 설정이 필요하고, 파이토치 설정 문서에서 참고하면 된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "e5qkyEEakpWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "q5pI5BHCncUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Check for GPU access with Pytorch"
      ],
      "metadata": {
        "id": "JU3ixmJnoNJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU access with Pytorch\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "YM_MGAqUoYc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device agnostic code\n",
        "# 왠만하면 agnostic code를 사용하는게 좋다.\n",
        "# GPU에 접근 가능하면 CUDA 사용 그렇지 않으면 CPU 사용\n",
        "device='cuda' if torch.cuda.is_available else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "5W6DDGn4ozHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()\n",
        "#이건 거대 대규모 데이터 세트에서 거대한 모델을 실행하는 경우에 많이 보임"
      ],
      "metadata": {
        "id": "bjTc5dkApfQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Putting tensor(and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
      ],
      "metadata": {
        "id": "A_Tf1nLjqODn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor(default on the CPU)\n",
        "tensor = torch.tensor([1,2,3],device='cpu')\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor,tensor.device)"
      ],
      "metadata": {
        "id": "AwMEDuEhqN49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to GPU(if available)\n",
        "\n",
        "tensor_on_gpu=tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "iFtxcZoErlnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Moving tensors back to the CPU(넘파이는 CPU에서만 작동하기 때문에)\n",
        "\n"
      ],
      "metadata": {
        "id": "EwL_lQMHsH0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform it to Numpy\n",
        "tensor_on_gpu.numpy() # Tensor not on right device"
      ],
      "metadata": {
        "id": "5bIbOmxWsWQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix the GPU tensor with Numpy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu=tensor_on_gpu.cpu().numpy() # tensor_on_gpu는 gpu상에 있어서 .cpu()로 gpu에있는 텐서를\n",
        "# CPU에다가 넣어준 후에 Tensor를 Numpy로 넘겨준 작업\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "id": "gxt9q5GNs3rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "xS3HOjjGtaCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise & Extra-curriculum"
      ],
      "metadata": {
        "id": "28SuUXdJ-9Lo"
      }
    }
  ]
}